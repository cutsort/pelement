
Normal Processing

I) Registration of Benchwork.

The normal procedure for experimental data is:
	a) registration of a plate of strains
	b) digestion
	c) ligation
	d) iPCR
	e) sequencing
	f) gels

Registering of each of these steps happens through a web interface by
Martha at the bench. There are typically 95 samples in a plate with
strain identifiers generated by Baylor. Each of these steps populates a
corresponding table in the database which records who and when the step
was done and the important associated details.

When the gels are done, Martha will send an email notifying the person
processing them.

II) Processing of the data.

The normal workflow of data depends on whether the data consists of new
or recheck sequences.

For either data type, the first step is to move the chromats from their
INBOX location to the archive directory space. This is done with a script
moveTraces.pl

For new data, the processing steps are:

	a) base calling
	b) sequence trimming
	c) sequence importing

For recheck data, the steps are:

	a) base calling
	b) sequence trimming
	c) consensus building
	d) recheck sequence importing

There are corresponding scripts baseCaller.pl, seqTrimmer.pl seqImporter.pl
and buildConsensus.pl. All of these take an argument '-gel <gel_name>'
Because of the routine nature of these processing steps, there is a
script to invoke these tasks gelMaster.pl. This takes as an argument a
list of gels to process (without a -gel option).

After processing the data, there is a step of blasting and aligning.
These are typically handled by the scripts runBlast.pl and alignSeq.pl
Again, from the routine nature of these, there is a master script
blastMaster.pl. It does not take an argument.


In summary, the normal processing flow is:

1) run moveTraces.pl

Check for gels that got transferred. They usually come in pairs.

2) run gelMaster.pl PT_gel1 PT_gel2

Check for abnormal behavior or many error messages

3) run blastMaster.pl

If this is a recheck batch, then you also need to run autoCurate:

4) autoCurate.pl -gel PT_gel1; autoCurate.pl -gel PT_gel2


III) Curation

Bob Levis is in charge of selecting the lines for the permanent
collection.  Interactions with him involve 3 steps:

1) After a new batch is sequenced, he will send a file listing the strain
names and a status update. This changes strains that have status 'new'
in the strain table to either 'permenent' or 'discard'. This file is
fed to the script processStatus.pl to update the strain table.

2) After a recheck batch is confirmed, Bob will send a list of strains
to be submitted to the permanent collection. First, the sequence of
these need to be submitted to GenBank. The usual command is

generateGenBankMail.pl -out <file_to_send> `cat <list_of_strains>`

Email the file to dbGSS and wait for an email response. This usually comes the next
day.

3) A second file from Bob will contain genotype/phenotype
information. These usually have the same strains as the previous file,
unless there were last minute decisions to add some. It's worthwhile
to proofread this file before importing it. I typically remove quotes
that appear in the comment fields, remove some spurious newlines, and
make sure the column headers match what is expected in the processing
script, importPhenotype.pl.


To submit to FlyBase, first process the accession numbers with
processGenbankAcc.pl. When the accession numbers have been loaded,
we can generate the FlyBase xml with the command

generateFlyBaseXML.pl -out <file_to_send> `cat <list_of_strains>`

Do a quick check on this file to be sure it contains the expected number
of strain entries. And see that the comments have made it into the xml.
At least at first, email it to Bob so that he can proofread it.

Email the final version to Lynn Crosby (crosby@morgan.harvard.edu)
and Kathleen Falls (falls@morgan.harvard.edu) and Bob.

Kathleen will email back a list of FlyBase accession numbers. These can
be processed with either processXML.pl or processXML_text.pl. The first
version was a grandiose xml parser. The second was a hack of the first
version that just deals with a text file. I've been using the second
version lately.
